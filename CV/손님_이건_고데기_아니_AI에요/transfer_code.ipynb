{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGTdwJhWOduj"
      },
      "source": [
        "## hairstyle transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/aiku/AIKU/hair/hairstyle_transfer\n"
          ]
        }
      ],
      "source": [
        "%cd /home/aiku/AIKU/hair/hairstyle_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OYeau0I-RLZV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import torch\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if os.path.exists('exp'):\n",
        "    shutil.rmtree('exp')\n",
        "    os.mkdir('exp')\n",
        "\n",
        "if os.path.exists('data'):\n",
        "    shutil.rmtree('data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8ko8Iz9fRAyV"
      },
      "outputs": [],
      "source": [
        "# source image(사용자 이미지)\n",
        "source_path = '/home/aiku/AIKU/hair/source6.jpg'\n",
        "img1 = Image.open(source_path)\n",
        "img1 = img1.resize((1024, 1024))\n",
        "img1.save('exp/source.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mtaWjnOcRAyZ"
      },
      "outputs": [],
      "source": [
        "# target image(헤어스타일 이미지)\n",
        "target_path = '/home/aiku/AIKU/hair/target8.png'\n",
        "img2 = Image.open(target_path)\n",
        "# img2 = img2.resize((1024, 1024))\n",
        "img2.save('exp/target.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from argparse import ArgumentParser\n",
        "from unittest import result\n",
        "\n",
        "from hairstyle_transfer_tool import Tool\n",
        "\n",
        "def run_inference(tool, mode, source, target, alpha_blend, n_steps_interp = None, face_interp = None):\n",
        "    if mode == 'transfer':\n",
        "        paths_to_results = tool.hairstyle_transfer(source, target, alpha_blend = alpha_blend)\n",
        "    elif mode == 'interp':\n",
        "        paths_to_results = tool.interpolation_single_pair(source, target, n_steps=n_steps_interp, interpolate_hair = not face_interp, alpha_blend = alpha_blend)\n",
        "    elif mode == 'manip':\n",
        "        paths_to_results = tool.hair_manipulation_single(source, args['manip_attribute'], coeffs=args['manip_strength'], alpha_blend= alpha_blend)\n",
        "    else:\n",
        "        raise 'Mode not recognized'\n",
        "    return paths_to_results\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # args = parse_args()\n",
        "#     print(f'All done')\n",
        "#     tool = Tool(opts=None, result_path='./data/results/', checkpoint_path='./best_model.pt')\n",
        "#     paths_to_results =run_inference(tool, mode='transfer',source='./exp/target.png', target='./exp/source.png', alpha_blend=True )\n",
        "#     print(f'Results saved as: {paths_to_results}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using BackboneEncoderUsingLastLayerIntoWPlus\n",
            "Using BackboneEncoderUsingLastLayerIntoWPlus\n",
            "Loading pSp from checkpoint: ./best_model.pt\n",
            "Number of faces detected: 1\n",
            "Detection 0: Left: 233 Top: 357 Right: 788 Bottom: 911\n",
            "Part 0: (240, 495), Part 1: (246, 567) ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of faces detected: 1\n",
            "Detection 0: Left: 233 Top: 295 Right: 788 Bottom: 850\n",
            "Part 0: (220, 450), Part 1: (226, 523) ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Lossy conversion from float64 to uint8. Range [0.0, 253.0]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'./data/results/target_source_blend_True.jpg'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_inference(tool=Tool(opts=None, result_path='./data/results/', checkpoint_path='./best_model.pt'),\n",
        "               mode='transfer', source='./exp/target.png', target='./exp/source.png', alpha_blend=True )"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "hair",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "641a6ac1301de007d9518d93ddfd1d063977fbccf7b1973ded65770e7d2dfcc4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
